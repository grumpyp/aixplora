from embeddings.basesplit import BaseSplit
import nltk

class TextSplitter(BaseSplit):
    """
    A class for splitting text into chunks using the NLTK library.

    The TextSplitter class extends the BaseSplit class and provides methods for splitting text into reasonable chunks.

    Args:
        text (str): The text to be split.
        context_type (ContextTypes): The type of context for text splitting.
        text_length (Callable[[str], int], optional): A function to calculate the length of the text. Defaults to len.

    Methods:
        split() -> None:
            Defined in `BaseSplit` as Abstract Method. Functionality not defined in this class.
        
        chunk_document():
            Chunks the document into sentences and processes them to extract phrases.

        extract_phrases(tree) -> List[str]:
            Recursively extracts phrases from a given NLTK tree.

    Example Usage:
    ```
        splitter = TextSplitter(text="Example text", context_type=ContextTypes.TEXT)
        chunks = splitter.split()
    ```
    """
    def __init__(self, text, context_type, text_length=len):
        """
        Initializes the TextSplitter object.

        Args:
            text (str): The text to be split.
            context_type (ContextTypes): The type of context for text splitting.
            text_length (Callable[[str], int], optional): A function to calculate the length of the text. Defaults to len.

        Returns:
            None
        """
        super().__init__(text, context_type, text_length)

    def split(self) -> None:
        """
        Split's file into chunks. Not currently implemented
        """
        pass

    def chunk_document(self) -> None:
        """
        Chunk the document into sentences and perform named entity recognition (NER) chunking.

        This method uses the NLTK library to perform text chunking. It requires the NLTK module to be installed
        and the necessary resources for tokenization and part-of-speech tagging to be downloaded.

        Returns:
            parsed_sentences (List[str]): A list of parsed sentences after chunking.
        """
        try:
            from nltk.chunk import ChunkParserI
            # download resources for tokenization and pos tagging
            nltk.download('punkt')
            nltk.download('averaged_perceptron_tagger')
            nltk.download('maxent_ne_chunker')
            nltk.download('words')
        except ImportError:
            raise ImportError("nltk module not installed")

        # Use NLTK's pre-trained sentence tokenizer
        sentences = nltk.sent_tokenize(self.text)

        parsed_sentences = []
        buffer = ""
        for sentence in sentences:
            # Add the current sentence to the buffer
            buffer += " " + sentence

            # Check if buffer already exceeds the desired length
            if len(buffer) > 1000:
                words = nltk.word_tokenize(buffer)
                tagged_words = nltk.pos_tag(words)
                chunks = nltk.ne_chunk(tagged_words)
                phrases = TextSplitter.extract_phrases(chunks)
                parsed_sentence = ' '.join(phrases)
                parsed_sentences.append(parsed_sentence)

                buffer = ""

        # Process any remaining sentences in the buffer
        if buffer:
            words = nltk.word_tokenize(buffer)
            tagged_words = nltk.pos_tag(words)
            chunks = nltk.ne_chunk(tagged_words)
            phrases = TextSplitter.extract_phrases(chunks)
            parsed_sentence = ' '.join(phrases)
            parsed_sentences.append(parsed_sentence)

        return parsed_sentences

    @staticmethod
    def extract_phrases(tree) -> list[str]:
        """
        Recursively extract phrases from a tree generated by chunking.

        Args:
            tree: The tree generated by chunking.

        Returns:
            phrases (List[str]): A list of extracted phrases.
        """
        phrases = []
        if hasattr(tree, 'label') and tree.label:
            for child in tree:
                phrases.extend(TextSplitter.extract_phrases(child))
        else:
            phrases.append(tree[0])
        return phrases